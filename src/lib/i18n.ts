/**
 * Internationalization (i18n) for Demo6
 * Supports Chinese and English
 */

export type Language = "zh" | "en";

export interface Translations {
  // Header
  title: string;
  subtitle: string;
  queueStats: string;
  waiting: string; // For queue stats
  processing: string;
  completed: string;
  failed: string;
  connected: string;
  queueServerDisconnected: string;

  // Sidebar - Tech Stack
  techStack: string;
  features: string;
  technology: string;
  architecture: string;
  coreFeatures: string;
  bunjs: string;
  bunjsDesc: string;
  bullmq: string;
  bullmqDesc: string;
  redis: string;
  redisDesc: string;
  ollama: string;
  ollamaDesc: string;
  sse: string;
  sseDesc: string;
  queueService: string;
  queueServiceDesc: string;
  redisService: string;
  redisServiceDesc: string;
  ollamaService: string;
  ollamaServiceDesc: string;

  // Features
  performanceMetrics: string;
  avgResponseTime: string;
  totalRequests: string;
  successRate: string;
  throughput: string;
  taskHistory: string;
  queueSettings: string;
  taskPriority: string;
  priorityLow: string;
  priorityMedium: string;
  priorityHigh: string;
  concurrency: string;
  maxRetries: string;
  rateLimit: string;
  noHistory: string;
  taskHistoryRecords: string;
  taskQueueManagement: string;
  realTimeProgress: string;
  priorityQueue: string;
  autoRetry: string;
  rateLimitFeature: string;
  concurrentProcessing: string;
  historyRecords: string;
  streamingResponse: string;
  performanceMonitoring: string;

  // Chat
  startChat: string;
  startChatDesc: string;
  feature1: string;
  feature2: string;
  feature3: string;
  feature4: string;
  you: string;
  aiAssistant: string;
  generatingQuestion: string;
  highPriority: string;
  queuePosition: string;
  queuePositionText: string;
  waitingInQueue: string;
  generatingResponse: string;
  generatingQuestionActive: string;
  generationFailed: string;
  waitingMessage: string;
  processingPercent: string;
  send: string;
  refresh: string;
  messageQueueInfo: string;
  priority: string;
  priorityText: string;
  aiGenerateQuestion: string;
  aiGenerateQuestionDesc: string;
  inputPlaceholder: string;
  enterToSend: string;

  // Status
  statusWaiting: string;
  statusProcessing: string;
  statusCompleted: string;
  statusFailed: string;
  queueAhead: string;
  tasks: string;
}

const translations: Record<Language, Translations> = {
  zh: {
    title: "Demo6: AI å¯¹è¯é˜Ÿåˆ—ç³»ç»Ÿ",
    subtitle: "åŸºäº Bun.js + BullMQ + Redis + Ollama çš„ä¼ä¸šçº§é˜Ÿåˆ—å¼ AI å¯¹è¯å¹³å°",
    queueStats: "å®æ—¶é˜Ÿåˆ—ç»Ÿè®¡",
    waiting: "ç­‰å¾…",
    processing: "å¤„ç†",
    completed: "å®Œæˆ",
    failed: "å¤±è´¥",
    connected: "å·²è¿æ¥",
    queueServerDisconnected: "é˜Ÿåˆ—æœåŠ¡å™¨æœªè¿æ¥",
    techStack: "æŠ€æœ¯æ ˆ",
    features: "åŠŸèƒ½",
    technology: "æŠ€æœ¯æ„æˆ",
    architecture: "æ¶æ„è®¾è®¡",
    coreFeatures: "æ ¸å¿ƒåŠŸèƒ½",
    bunjs: "Bun.js",
    bunjsDesc: "é«˜æ€§èƒ½ JavaScript è¿è¡Œæ—¶ï¼ŒåŸç”Ÿæ”¯æŒ TypeScriptã€WebSocketã€SSEï¼Œå¯åŠ¨é€Ÿåº¦æ¯” Node.js å¿« 4x",
    bullmq: "BullMQ",
    bullmqDesc: "åŸºäº Redis çš„ç°ä»£é˜Ÿåˆ—ç³»ç»Ÿï¼Œæ”¯æŒä¼˜å…ˆçº§ã€å»¶è¿Ÿã€é‡è¯•ã€é€Ÿç‡é™åˆ¶",
    redis: "Redis",
    redisDesc: "å†…å­˜æ•°æ®åº“ï¼Œä½œä¸ºé˜Ÿåˆ—åç«¯ï¼Œæä¾›æŒä¹…åŒ–å’Œé«˜å¯ç”¨æ€§",
    ollama: "Ollama",
    ollamaDesc: "æœ¬åœ°å¤§è¯­è¨€æ¨¡å‹æœåŠ¡ï¼Œä½¿ç”¨ qwen3:latest æ¨¡å‹ï¼Œæ”¯æŒæµå¼ç”Ÿæˆ",
    sse: "SSE",
    sseDesc: "Server-Sent Events å®ç°å®æ—¶çŠ¶æ€æ¨é€ï¼Œæ— éœ€ WebSocketï¼Œè‡ªåŠ¨é‡è¿",
    queueService: "é˜Ÿåˆ—æœåŠ¡ (Port 3001)",
    queueServiceDesc: "ç‹¬ç«‹çš„ Bun æœåŠ¡å™¨ï¼Œå¤„ç†ä»»åŠ¡å…¥é˜Ÿã€çŠ¶æ€æŸ¥è¯¢ã€SSE æ¨é€",
    redisService: "Redis (Port 6379)",
    redisServiceDesc: "å­˜å‚¨é˜Ÿåˆ—æ•°æ®ã€ä»»åŠ¡çŠ¶æ€ã€æ”¯æŒæŒä¹…åŒ–",
    ollamaService: "Ollama (Port 11434)",
    ollamaServiceDesc: "æœ¬åœ° LLM æœåŠ¡ï¼ŒWorker è¿›ç¨‹å¼‚æ­¥è°ƒç”¨ç”Ÿæˆå“åº”",
    performanceMetrics: "æ€§èƒ½æŒ‡æ ‡",
    avgResponseTime: "å¹³å‡å“åº”æ—¶é—´",
    totalRequests: "æ€»è¯·æ±‚æ•°",
    successRate: "æˆåŠŸç‡",
    throughput: "ååé‡",
    taskHistory: "ä»»åŠ¡å†å²",
    queueSettings: "é˜Ÿåˆ—è®¾ç½®",
    taskPriority: "ä»»åŠ¡ä¼˜å…ˆçº§",
    priorityLow: "ä½ (1)",
    priorityMedium: "ä¸­ (5)",
    priorityHigh: "é«˜ (10)",
    concurrency: "å¹¶å‘å¤„ç†æ•°",
    maxRetries: "æœ€å¤§é‡è¯•æ¬¡æ•°",
    rateLimit: "é€Ÿç‡é™åˆ¶",
    startChat: "å¼€å§‹ AI å¯¹è¯",
    startChatDesc: "è¾“å…¥ä½ çš„é—®é¢˜ï¼Œæ¶ˆæ¯å°†è¿›å…¥é˜Ÿåˆ—ç³»ç»Ÿï¼Œå®æ—¶æ˜¾ç¤ºå¤„ç†çŠ¶æ€å’Œè¿›åº¦",
    feature1: "âœ¨ æ”¯æŒä¼˜å…ˆçº§é˜Ÿåˆ—ç®¡ç†",
    feature2: "âš¡ å®æ—¶è¿›åº¦è¿½è¸ª",
    feature3: "ğŸ”„ è‡ªåŠ¨é‡è¯•æœºåˆ¶",
    feature4: "ğŸ“Š æ€§èƒ½ç›‘æ§",
    you: "ä½ ",
    aiAssistant: "AI åŠ©æ‰‹",
    generatingQuestion: "ç”Ÿæˆé—®é¢˜ä¸­",
    highPriority: "é«˜ä¼˜å…ˆçº§",
    queuePosition: "é˜Ÿåˆ—",
    queuePositionText: "å‰{count}ä¸ª",
    waitingInQueue: "é˜Ÿåˆ—ä¸­ï¼Œå‰é¢è¿˜æœ‰ {count} ä¸ªä»»åŠ¡...",
    generatingResponse: "æ­£åœ¨ç”Ÿæˆå“åº”...",
    generatingQuestionActive: "æ­£åœ¨ç”Ÿæˆé—®é¢˜...",
    generationFailed: "ç”Ÿæˆå¤±è´¥",
    waitingMessage: "ç­‰å¾…é˜Ÿåˆ—å¤„ç†...",
    processingPercent: "å¤„ç†ä¸­: {percent}%",
    send: "å‘é€",
    refresh: "åˆ·æ–°",
    messageQueueInfo: "æ¶ˆæ¯å°†è¿›å…¥é˜Ÿåˆ—ï¼Œæ”¯æŒå¹¶å‘å¤„ç†ï¼Œå®æ—¶æ˜¾ç¤ºè¿›åº¦",
    priority: "ä¼˜å…ˆçº§",
    priorityText: "{level}",
    aiGenerateQuestion: "AI ç”Ÿæˆé—®é¢˜",
    aiGenerateQuestionDesc: "ç‚¹å‡»ç”Ÿæˆéšæœºé—®é¢˜ï¼Œæ¶µç›–æŠ€æœ¯ã€å•†ä¸šã€åˆ›æ„ç­‰ä¸»é¢˜",
    inputPlaceholder: "è¾“å…¥ä½ çš„é—®é¢˜... (æŒ‰ Enter å‘é€ï¼ŒShift+Enter æ¢è¡Œ)",
    enterToSend: "æŒ‰ Enter å‘é€ï¼ŒShift+Enter æ¢è¡Œ",
    statusWaiting: "é˜Ÿåˆ—ä¸­",
    statusProcessing: "ç”Ÿæˆä¸­",
    statusCompleted: "å®Œæˆ",
    statusFailed: "å¤±è´¥",
    queueAhead: "é˜Ÿåˆ—ä¸­ï¼Œå‰é¢è¿˜æœ‰",
    tasks: "ä¸ªä»»åŠ¡...",
    noHistory: "æš‚æ— å†å²è®°å½•",
    taskHistoryRecords: "ä»»åŠ¡å†å²è®°å½•ï¼ˆæœ€è¿‘ 50 æ¡ï¼‰",
    taskQueueManagement: "ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†ï¼ˆç­‰å¾…/å¤„ç†/å®Œæˆï¼‰",
    realTimeProgress: "å®æ—¶è¿›åº¦è¿½è¸ªï¼ˆ0-100%ï¼‰",
    priorityQueue: "ä¼˜å…ˆçº§é˜Ÿåˆ—ï¼ˆé«˜/ä¸­/ä½ï¼‰",
    autoRetry: "è‡ªåŠ¨é‡è¯•æœºåˆ¶ï¼ˆå¤±è´¥è‡ªåŠ¨é‡è¯• 3 æ¬¡ï¼‰",
    rateLimitFeature: "é€Ÿç‡é™åˆ¶ï¼ˆé˜²æ­¢ API è¿‡è½½ï¼‰",
    concurrentProcessing: "å¹¶å‘å¤„ç†ï¼ˆåŒæ—¶å¤„ç† 3 ä¸ªä»»åŠ¡ï¼‰",
    historyRecords: "ä»»åŠ¡å†å²è®°å½•ï¼ˆæœ€è¿‘ 50 æ¡ï¼‰",
    streamingResponse: "æµå¼å“åº”ï¼ˆSSE å®æ—¶æ¨é€ï¼‰",
    performanceMonitoring: "æ€§èƒ½ç›‘æ§ï¼ˆå“åº”æ—¶é—´ã€æˆåŠŸç‡ï¼‰",
  },
  en: {
    title: "Demo6: AI Chat Queue System",
    subtitle: "Enterprise-grade queue-based AI chat platform built with Bun.js + BullMQ + Redis + Ollama",
    queueStats: "Real-time Queue Stats",
    waiting: "Waiting",
    processing: "Processing",
    completed: "Completed",
    failed: "Failed",
    connected: "Connected",
    queueServerDisconnected: "Queue Server Disconnected",
    techStack: "Tech Stack",
    features: "Features",
    technology: "Technology",
    architecture: "Architecture",
    coreFeatures: "Core Features",
    bunjs: "Bun.js",
    bunjsDesc: "High-performance JavaScript runtime with native TypeScript, WebSocket, SSE support, 4x faster startup than Node.js",
    bullmq: "BullMQ",
    bullmqDesc: "Modern queue system based on Redis, supports priority, delay, retry, rate limiting",
    redis: "Redis",
    redisDesc: "In-memory database serving as queue backend, provides persistence and high availability",
    ollama: "Ollama",
    ollamaDesc: "Local large language model service using qwen3:latest model, supports streaming generation",
    sse: "SSE",
    sseDesc: "Server-Sent Events for real-time status push, no WebSocket needed, auto-reconnect",
    queueService: "Queue Service (Port 3001)",
    queueServiceDesc: "Standalone Bun server handling task queuing, status queries, SSE push",
    redisService: "Redis (Port 6379)",
    redisServiceDesc: "Stores queue data, task status, supports persistence",
    ollamaService: "Ollama (Port 11434)",
    ollamaServiceDesc: "Local LLM service, Worker processes asynchronously call to generate responses",
    performanceMetrics: "Performance Metrics",
    avgResponseTime: "Avg Response Time",
    totalRequests: "Total Requests",
    successRate: "Success Rate",
    throughput: "Throughput",
    taskHistory: "Task History",
    queueSettings: "Queue Settings",
    taskPriority: "Task Priority",
    priorityLow: "Low (1)",
    priorityMedium: "Medium (5)",
    priorityHigh: "High (10)",
    concurrency: "Concurrency",
    maxRetries: "Max Retries",
    rateLimit: "Rate Limit",
    startChat: "Start AI Chat",
    startChatDesc: "Enter your question, messages will enter the queue system with real-time status and progress",
    feature1: "âœ¨ Priority queue management",
    feature2: "âš¡ Real-time progress tracking",
    feature3: "ğŸ”„ Auto retry mechanism",
    feature4: "ğŸ“Š Performance monitoring",
    you: "You",
    aiAssistant: "AI Assistant",
    generatingQuestion: "Generating Question",
    highPriority: "High Priority",
    queuePosition: "Queue",
    queuePositionText: "{count} ahead",
    waitingInQueue: "â³ In queue, {count} tasks ahead...",
    generatingResponse: "âš™ï¸ Generating response...",
    generatingQuestionActive: "âš™ï¸ Generating question...",
    generationFailed: "âŒ Generation failed",
    waitingMessage: "â³ Waiting for queue processing...",
    processingPercent: "Processing: {percent}%",
    send: "Send",
    refresh: "Refresh",
    messageQueueInfo: "Messages will enter queue, support concurrent processing, real-time progress display",
    priority: "Priority",
    priorityText: "{level}",
    aiGenerateQuestion: "AI Generate Question",
    aiGenerateQuestionDesc: "Click to generate random questions covering tech, business, creative topics",
    inputPlaceholder: "Enter your question... (Press Enter to send, Shift+Enter for new line)",
    enterToSend: "Press Enter to send, Shift+Enter for new line",
    statusWaiting: "In Queue",
    statusProcessing: "Processing",
    statusCompleted: "Completed",
    statusFailed: "Failed",
    queueAhead: "In queue,",
    tasks: "tasks ahead...",
    noHistory: "No history records",
    taskHistoryRecords: "Task History (Last 50)",
    taskQueueManagement: "Task queue management (Waiting/Processing/Completed)",
    realTimeProgress: "Real-time progress tracking (0-100%)",
    priorityQueue: "Priority queue (High/Medium/Low)",
    autoRetry: "Auto retry mechanism (3 retries on failure)",
    rateLimitFeature: "Rate limiting (prevent API overload)",
    concurrentProcessing: "Concurrent processing (3 tasks simultaneously)",
    historyRecords: "Task History (Last 50)",
    streamingResponse: "Streaming response (SSE real-time push)",
    performanceMonitoring: "Performance monitoring (response time, success rate)",
  },
};

export function useTranslations(lang: Language) {
  const t = translations[lang];
  
  return {
    t,
    lang,
    // Helper function to format strings with placeholders
    format: (key: keyof Translations, params?: Record<string, string | number>) => {
      let text = t[key];
      if (params) {
        Object.entries(params).forEach(([key, value]) => {
          text = text.replace(`{${key}}`, String(value));
        });
      }
      return text;
    },
  };
}

